{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5a3f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal,osr\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca34733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "def r2(y_true, y_pred):\n",
    "    a = K.square(y_pred - y_true)\n",
    "    b = K.sum(a)\n",
    "    c = K.mean(y_true)\n",
    "    d = K.square(y_true - c)\n",
    "    e = K.sum(d)\n",
    "    f = 1 - b / e\n",
    "    return f\n",
    "\n",
    "def Write_Tiff_optimize(outname, data, X_size, Y_size, lon_min, lat_max, resolution, NoData_value=None):\n",
    "    import os\n",
    "    (filepath, tempfilename) = os.path.split(outname)\n",
    "    if os.path.exists(filepath) == False:\n",
    "        os.makedirs(filepath)\n",
    "    ds = gdal.GetDriverByName('Gtiff').Create(outname, int(X_size), int(Y_size), 1, gdal.GDT_Float32)\n",
    "    geotransfrom = (lon_min, resolution, 0, lat_max, 0, -resolution)\n",
    "    ds.SetGeoTransform(geotransfrom)\n",
    "    srs = osr.SpatialReference()\n",
    "    srs.ImportFromEPSG(4326)\n",
    "    ds.SetProjection(srs.ExportToWkt())\n",
    "    ds.GetRasterBand(1).WriteArray(data)\n",
    "    if NoData_value != None:\n",
    "        ds.GetRasterBand(1).SetNoDataValue(NoData_value)\n",
    "    ds.FlushCache()\n",
    "    ds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9957f5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(r\"*.h5\", custom_objects={'r2':r2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad2b496-3467-4421-ab0f-3d89f4456cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(r\"*.csv\")\n",
    "X = train_data.iloc[:, 1:11]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751917c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_directory = r\"\"\n",
    "out_directory = r\"\"\n",
    "year = 2000\n",
    "Albedo_list = np.array(sorted(glob.glob(file_directory + \"//Albedo//\" + str(year) + \"\\*.tiff\")))\n",
    "LAI_list = np.array(sorted(glob.glob(file_directory + \"//LAI//\" + str(year) + \"\\*.tif\")))\n",
    "r_list = np.array(sorted(glob.glob(file_directory + \"//r//\" + str(year) + \"\\*.tiff\")))\n",
    "sp_list = np.array(sorted(glob.glob(file_directory + \"//sp//\" + str(year) + \"\\*.tiff\")))\n",
    "# SSR_list = np.array(sorted(glob.glob(file_directory + \"//SSR//\" + str(year) + \"\\*.tif\")))\n",
    "strd_list = np.array(sorted(glob.glob(file_directory + \"//strd//\" + str(year) + \"\\*.tiff\")))\n",
    "ssrd_list = np.array(sorted(glob.glob(file_directory + \"//ssrd//\" + str(year) + \"\\*.tiff\")))\n",
    "t2m_list = np.array(sorted(glob.glob(file_directory + \"//t2m//\" + str(year) + \"\\*.tiff\")))\n",
    "ws_list = np.array(sorted(glob.glob(file_directory + \"//ws//\" + str(year) + \"\\*.tif\")))\n",
    "dem = r\"\"\n",
    "landcover = \"\"\n",
    "landcover_data = gdal.Open(landcover).ReadAsArray().reshape(-1)\n",
    "mete_region = r\"\"\n",
    "mete_region_data = gdal.Open(mete_region).ReadAsArray().reshape(-1)\n",
    "china_region = gdal.Open(r\"\").ReadAsArray().reshape(-1)\n",
    "file_directory = r\"\"\n",
    "LEc_list = np.array(sorted(glob.glob(file_directory + \"//LE_C//\" + \"\\*.tif\")))\n",
    "LEs_list = np.array(sorted(glob.glob(file_directory + \"//LE_S//\" + \"\\*.tif\")))\n",
    "date_list = np.array([Albedo_list[i].split(\"_\")[-2].split(\".\")[0] for i in range(len(Albedo_list))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd6f6fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for file_i in range(0,366):\n",
    "    Albedo_data = gdal.Open(Albedo_list[file_i]).ReadAsArray()\n",
    "    shape = Albedo_data.shape\n",
    "    Albedo_data = Albedo_data.reshape(-1)\n",
    "    LAI_data = gdal.Open(LAI_list[file_i]).ReadAsArray().reshape(-1)\n",
    "    r_data = gdal.Open(r_list[file_i]).ReadAsArray().reshape(-1)\n",
    "    sp_data = gdal.Open(sp_list[file_i]).ReadAsArray().reshape(-1)\n",
    "    # SSR_data = gdal.Open(SSR_list[file_i]).ReadAsArray().reshape(-1)\n",
    "    ssrd_data = gdal.Open(ssrd_list[file_i]).ReadAsArray().reshape(-1)\n",
    "    strd_data = gdal.Open(strd_list[file_i]).ReadAsArray().reshape(-1)\n",
    "    t2m_data = gdal.Open(t2m_list[file_i]).ReadAsArray().reshape(-1)\n",
    "    ws_data = gdal.Open(ws_list[file_i]).ReadAsArray().reshape(-1)\n",
    "    dem_data = gdal.Open(dem).ReadAsArray().reshape(-1)\n",
    "    landcover_data = gdal.Open(landcover).ReadAsArray().reshape(-1)\n",
    "    \n",
    "    LEc_data = gdal.Open(LEc_list[file_i]).ReadAsArray().reshape(-1)\n",
    "    LEs_data = gdal.Open(LEs_list[file_i]).ReadAsArray().reshape(-1)\n",
    "    LE_data = LEc_data + LEs_data\n",
    "    print(LEs_list[file_i],LEc_list[file_i],date_list[file_i],\"_begin\")\n",
    "\n",
    "    Mask = np.ones(Albedo_data.shape).astype(bool)\n",
    "    Mask &= LE_data == 0\n",
    "    Mask &= china_region == 1\n",
    "    data = [Albedo_data[Mask],LAI_data[Mask],r_data[Mask],sp_data[Mask],ssrd_data[Mask],\n",
    "            strd_data[Mask],t2m_data[Mask],ws_data[Mask],dem_data[Mask],landcover_data[Mask]]\n",
    "    data=np.stack(data, 1)\n",
    "    data = ((data - np.mean(X).values)/np.std(X).values)\n",
    "    print(date_list[file_i],\"_run\")\n",
    "    predict = model.predict(data)\n",
    "    \n",
    "    LEc_data[Mask] = predict[:,0]\n",
    "    LEs_data[Mask] = predict[:,1]\n",
    "        LEc_data = LEc_data.reshape(shape)\n",
    "    LEs_data = LEs_data.reshape(shape)\n",
    "    LE_data = LEc_data + LEs_data\n",
    "    LE_data[LE_data <= 0] = 0\n",
    "    LEc_data[LE_data <= 0] = 0\n",
    "    LEs_data[LE_data <= 0] = 0\n",
    "     \n",
    "    outname = out_directory + '\\\\'+'LEc_DNN_'+date_list[file_i]+'.tif'\n",
    "    Write_Tiff_optimize(outname, LEc_data, shape[1], shape[0], 73.0, 55.0, 0.01, 0)\n",
    "    outname = out_directory + '\\\\'+'LEs_DNN_'+date_list[file_i]+'.tif'\n",
    "    Write_Tiff_optimize(outname, LEs_data, shape[1], shape[0], 73.0, 55.0, 0.01, 0)\n",
    "    outname = out_directory + '\\\\'+'LE_DNN_'+date_list[file_i]+'.tif'\n",
    "    Write_Tiff_optimize(outname, LE_data, shape[1], shape[0], 73.0, 55.0, 0.01, 0)\n",
    "    print(date_list[file_i],\"_finish\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
